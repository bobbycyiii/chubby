\documentclass[10pt]{article}
\usepackage{noweb}
\noweboptions{smallcode,longchunks}
\usepackage{geometry}
\usepackage{amssymb,amsmath,amsthm,graphicx}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{construction}[theorem]{Construction}

\theoremstyle{plain}
\newtheorem*{claim}{Claim}
\newtheorem*{program}{Program}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{definitions}[theorem]{Definitions}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{example}[theorem]{Example}
\newtheorem{examples}[theorem]{Examples}
\newtheorem{remark}[theorem]{Remark}
\numberwithin{equation}{section}
\newcommand{\MOM}{\textsc{Mom}}
\begin{document}
\pagestyle{noweb}
\title{[[nonelem]]}
\author{Robert C. Haraway III}
\date{\today}
\maketitle
\section*{Conventions}
We use camel-case naming, following Regina.
<<neckl.py>>=
from regina import Triangulation3, Perm4
@ 
\section{Necklace gluings with $n$ beads}
\begin{definition}
An $n$-dipyramid is a 3-ball with a cell structure
whose boundary triangulation is the suspension
of an $n$-gon. The choice of suspension points
is canonical unless $n = 4$, in which case we
take care to remember which vertices are suspension points.
\end{definition}
The following is our implementation of this
definition in Regina.
<<how to make an n-dipyr>>=
def makeDipyr(n):
        """Returns an n-dipyr."""
        newt = Triangulation3()
        for i in range(0,n):
                newt.newTetrahedron()
        for i in range(0,n):
                me = newt.simplex(i)
                you = newt.simplex((i+1)%n)
                me.join(2,you,Perm4(2,3))
        return newt
<<neckl.py>>=
<<how to make an n-dipyr>>
@
As you can verify, we have glued up the $n$-dipyramid so
that the interior faces are all faces 2 and 3 of their
respective tetrahedra, and the boundary faces are thus faces
0 and 1. Their common edge in a given tetrahedron is an edge
of the base polygon. We have also indexed the tetrahedra
with naturals less than $n$ so that the induced cyclic
ordering on the common edges is the same as that induced
by the base polygon. Finally, as you may verify, all the
0 faces lie around one suspension point, and the 1 faces
lie around the other suspension point.
@
N.B. In the above paragraph, the labels 0,1,2,3 refer to
Regina's internal labelling system, not our just imposed
face labelling on the boundary faces of the dipyramid.
@
\begin{definition}
  A \emph{necklace gluing of bead number $n$}
  is a oriented face-pairing
  of all the faces of an $n$-dipyramid
  such that every face-pair preserves the partition
  of the dipyramid's vertices
  into suspension points '' points.
\end{definition}
The set of necklace gluings
of bead number $n$ on an $n$-dipyramid
is naturally in bijection
with the fixed-point-free involutions
on the set of faces of that $n$-dipyramid.
There are $2 \cdot n$ faces, so given any
labelling of the faces by naturals less
than $2 \cdot n$, we get an identification
sending fixed-point-free involutions
in $S_{2 \cdot n}$ to necklace gluings. 
@
The labelling we choose involves a choice
of higher and lower suspension point, an
orientation of the base polygon, and
a choice of face thereon. With these choices,
mark the sides of the base polygon
with $\{2\cdot i : 0 \leq i < n\}$, such that
the chosen face takes marking 0, and
the cyclic ordering on faces from the
orientation induces the natural cyclic
ordering $0 < 2 < \cdots < 2\cdot n - 2$.
Then a face of the $n$-dipyramid which
is adjacent to the lower suspension point
takes as a label the marking on the side of
the base of which it is a cone, but a face of the
$n$-dipyramid adjacent to the higher
suspension point takes instead $1$ plus
the marking on its base side. (Cf. Figure \ref{fig:bead5}.)
@
%\begin{figure}
%\centering
%\includegraphics[width=.4\textwidth]{dipyr5.png}
%\caption{Our labelled 5-dipyramid in stereographic projection
%from the higher suspension point.}\label{fig:bead5}
%\end{figure}
@
Therefore, the following code accomplishes a necklace
gluing, given a fixed-point-free involution in
$S_{2\cdot n}$ in cycle notation,
assuming Regina maintains the indexing of tetrahedra.

First, it is easy to match a face label with a tetrahedron index.
<<neckl.py>>=
<<how to make a necklace gluing>>

<<how to make a necklace gluing>>=
def whichTet(face):
    return face / 2
@
We represent face-pairings as lists of pairs
of natural numbers. To accomplish a gluing,
we make an appropriate dipyramid, and for every
pair in the list, glue the faces together.
The first task is to determine which tetrahedras'
faces are getting glued together.

<<how to make a necklace gluing>>=
def makeNecklace(fpfinv):
    n = len(fpfinv)
    ndipyr = makeDipyr(n)
    local = list(fpfinv)
    while local != []:
        (i,j) = local.pop()
        me = ndipyr.simplex(whichTet(i))
        you = ndipyr.simplex(whichTet(j))
        
@
The face of [[me]] getting glued is
either 0 or 1, respectively, according
as $i$ is adjacent to the lower or
higher suspension point, i.e. according
as $i$ is even or odd.
<<how to make a necklace gluing>>=
        meFace = i % 2
@
We now split into two cases according as
$i,j$ lie on the same or different suspension points.

If they lie along the same suspension point, then
the face-pairing restricted to the vertices fixes
0 and 1. (Recall the duality between faces and
vertices of a tetrahedron.) 
But it must reverse orientation, so that
the whole manifold is oriented. Thus the induced
map on the vertices is the permutation $(2\ 3)$.
<<how to make a necklace gluing>>=
        if (i % 2 == j % 2):
            me.join(meFace,you,Perm4(2,3))
@
On the other hand, if they lie along different
suspension points, then the 0,1 vertices must
be flipped. Thus the 2 and 3 vertices must be
fixed so that the gluing is oriented.
<<how to make a necklace gluing>>=
        else:
            me.join(meFace,you,Perm4(0,1))
    ndipyr.setLabel(str(fpfinv))
    return ndipyr
@
\section{Enumerating necklace gluings}
Our next goal is to get a list as small as
possible which for every necklace gluing
contains a manifold homeomorphic to that gluing. We
could, of course, just enumerate all
fixed-point-free involutions and put the
associated gluings in a list. But many of
these, presumably, will be asymmetric, so
that by applying elements of the symmetry
group of the $n$-dipyramid, we get different
gluings which are homeomorphic. We wish to
eliminate as much of such redundancy as we
reasonably can.
@
A reasonable approach is to have our list
contain one representative from each
dipyr-symmetry group orbit of fixed-point-free
involutions, and nothing else. Milley took
this approach, and it is the approach we take
as well. However, we introduce a subtlety which
makes the enumeration faster and leaner.
@
We do not begin by enumerating all
fixed-point-free involutions as Milley does.
Instead, we begin by constructing a tree
with a face-pair at each internal node, such
that there is an identification of fixed-point-free
involutions in $S_{2\cdot n}$ with
backtrack-free paths from the root of the tree to leaves.
This takes much less space to store than the
whole list of fixed-point-free involutions.
We define what it means to remove an involution
from the tree. This takes much less time
than removing an involution from a list.
Finally, we do the most natural thing after that:
while the tree still contains an involution $\sigma$,
remove every element of $\sigma$'s orbit from the tree,
and then do something with $\sigma$ (e.g. put $\sigma$
in some list, or determine whether or not it represents
a hyperbolic 3-manifold).
@
Let us call the dipyramidal symmetry group $DP$. Our
first order of business is encoding its action on face-pairings.
It also acts on face-pairs and, of course, on faces. Since it
acts on several things at once, we have different functions
associated to these actions. But let us begin with how $DP$
acts on faces.
@
\begin{definition}
A face we represent as a natural number below $2 \cdot n$.
There are three symmetries of the dipyramid which generate
its symmetry group and are relatively easy to write down:
a counterclockwise rotation by an $n$th of a revolution;
the reflection through the plane through the base, which we
call a \emph{p-flip}; and
a reflection through a plane through the suspension points
and a lateral vertex, which we call a \emph{v-flip}. If
that lateral vertex is adjacent to faces $0,1,2\cdot(n-1), 2\cdot n - 1$,
then we call it \emph{the} v-flip.
\end{definition}
@
\begin{proposition}
  The following implements these symmetries as
  they act on face labels. For convenience, we implement the
  rotation through $t$ $n$ths of a revolution.
  \end{proposition}
@
<<how to act>>=
def rt(n,t,face):
    return (face + 2*t) % (2*n)

def pFlip(face):
    return face + 1 - 2*(face%2)

def vFlip(n,face):
    return 2*(n-1 + face%2) - face

<<neckl.py>>=
<<how to act>>
@
You may check that a symmetry of the dipyramid
is a rotation followed possibly by the p-flip,
followed possibly by the v-flip. (We also
remind the reader that in Python, [[m % n]]
is the remainder upon division of $m$ by $n$,
at least 0 and less than $n$.)
@
Because $DP$ acts on so many things,
we introduce a poor man's datatype to
represent its elements. We represent
an element of $DP$ by a pair [[(s,t)]]
of a string and number, where the string
[[str]] must be one of [["Rot"]],
[["PRot"]], [["VRot"]], or [["VPRot"]], and
the number [[t]] is assumed less than $n$.
@
<<how to act>>=
def actFace (n,dp,face):
    (s,t) = dp
    r = rt(n,t,face)
    if s == "Rot":
        return r
    if s == "VRot":
        return vFlip(n,r)
    if s == "PRot":
        return pFlip(r)
    if s == "VPRot":
        return vFlip(n,pFlip(r))
    else:
        raise Exception
@
Now, to discuss the action on face-pairs, we must
discuss our representation of face-pairs. We represent
them not just as ordered pairs, but as consistently
ordered pairs. We represent the pair of faces $i,j$
by $(i,j)$ or $(j,i)$ according as $i > j$ or $j > i$,
respectively.
@
Therefore, the implementation of the action on face-pairs
is not as simple as applying the action to each entry; we
have to maintain the order's consistency.
@
<<how to act>>=
def actFacePair(n,dp,facepair):
    (i,j) = facepair
    a_f = actFace
    (x,y) = (a_f (n,dp,i), a_f(n,dp,j))
    if x > y:
        return (x,y)
    else:
        return (y,x)
@
Finally, we represent a gluing as a $>$-sorted list
of face-pairs. So we have to sort
after applying the action on face-pairs.
@
<<how to act>>=
def actGluing(n,dp,gluing):
    afp = actFacePair
    unsorted = map((lambda fp: afp(n,dp,fp)), \
                                 gluing)
    return sorted(unsorted, reverse=True)
@
Having defined the action on gluings, we define
the orbit. We only make sure that the list
returned contains all elements from the orbit,
and only elements from the orbit. We do not
remove duplicates from this list.
@
<<how to orbit>>=
def orbitWithRepeats(n,gluing):
    l = gluing
    nums = range(n)
    nums.reverse()
    ag = actGluing
    symm_types = ["Rot","VRot","PRot","VPRot"]
    out = []
    for s in symm_types:
        for t in nums:
            out = [ag(n,(s,t),l)] + out
    return out
<<neckl.py>>=
<<how to orbit>>
@
Our tree will be a pretty standard binary tree on
pairs of natural numbers. Its type's definition in Haskell
would be
<<Haskell definition of the type of our tree>>=
data PT = PTLeaf | PTBranch (Integer,Integer) PT PT
@
That is to say, a pair-tree is either a leaf, or it's
a branch, with an associated pair $(m,n)$ of integers and
two associated pair-trees, a left child and right child.
We again go with a poor-man's implementation of this
datatype in Python. A pair-tree will be a tuple,
either a singleton or a quadruple. If it is a
singleton, its single entry will be the string [["PTLeaf"]].
Otherwise, its initial entry will be the string [["PTBranch"]];
its next entry will be a pair [[(m,n)]] of integers; and
its final entries will be pair-trees.
@
The way we construct our tree follows from a more general
construction of fixed-point-free involutions on arbitrary
lists of even length. Suppose $fpf(l)$ were the set of
fixed-point-free involutions on $l$. If $l$ is empty,
then this set is empty; we thus represent it by a leaf.
Otherwise, $l$ has at least two elements by evenness.
We partition $fpf(l)$ according as an element does or
does not flip the first two elements of $l$. Thus,
$fpf(l) = (f\ f') \cdot fpf(l'')\ \cup\ X$, where
$f,f'$ are the first elements of $l$; $l''$ is $l$
without these elements; and $X$ is the subset of
$fpf(l)$ sending $f$ to something apart from $f'$.
@
At this point we end up with two options.
Either we could use a non-binary tree, or we can
introduce a sort of auxiliary stack parameter in $fpf$
to "remember" which face-pairs we've foregone so far.
Because our proof assistant Coq did not agree with
non-binary trees, we choose the latter option.
@
So we end up with a slightly more complicated
decomposition. We have some set $m$, and
$fpf(l,m)$ is going to be the set of
fixed-point-free involutions on $l \cup m$ \emph{which
sends the first element of l to some other element of l}.
(Thus, our original definition of $fpf$ would
now be $fpf(l,\emptyset)$.)
If $l$ is empty, this is $\emptyset$. We represent
this situation by a leaf.
Otherwise, by $l$'s evenness, it has two
initial elements $f,f'$. Then we may decompose
$fpf(l,m)$ into those involutions which flip
$f,f'$ and those which don't.
We may write a fixed-point-free involution on $l\cup m$
which flips $f,f'$ as the composition of $(f\ f')$ and a
fixed-point-free involution of $l'' \cup m$,
where $l''$ is $l$ without $f,f'$. On the other
hand, a fixed-point-free involution on $l \cup m$
which does not send $f$ to $f'$ but which does send
$f$ into $l$ is a fixed-point-free involution on
$l' \cup (\{f'\} \cup m)$ which sends $f$ 
into some other element of $l'$,
where $l'$ is $l$ without $f'$. Thus we have 
a particular pair $(f,f')$, and two similar, simpler
$fpf$s to consider. We represent this situation by
a branch. (For convenience,
we define an auxiliary ``smush'' function establishing union
in the first part of the partition.)
@
<<how to make a prefix tree>>=
def smush (l,m):
    if m == []:
        return l
    else:
        return smush (([m[0]] + l), m[1:])

def fpf(l,m):
    if l == []:
        return ("PTLeaf",)
    # else
    f = l[0]
    lp = l[1:]
    if lp == []:
        return ("PTLeaf",)
    fp = l[1]
    lpp = l[2:]
    return ("PTBranch", \
            (f,fp), \
            fpf(smush(lpp,m), []), \
            fpf([f] + lpp, [fp] + m))
    
def originalTree(n):
    nums = range(2*n)
    nums.reverse()
    return fpf(nums, [])
<<neckl.py>>=
<<how to make a prefix tree>>
@
It's pretty simple to extract at least one involution
from our tree if there is one. Just go left.
@
<<how to get an involution if there is one>>=
def leftInvolution(pt):
    if pt[0] == "PTLeaf":
        return []
    else:
        (str, p, lt, rt) = pt
        assert str == "PTBranch"
        return [p] + leftInvolution(lt)
<<neckl.py>>=
<<how to get an involution if there is one>>
@
It's also fairly straightforward to remove
an involution from our tree. This, however,
requires now that we spell out exactly what
is the association between a path from root to
leaf and fixed-point-free involution. By cycle
notation it will suffice to describe how to
extract from such a path a sequence of $n$
face-pairs (in order to get a permutation in cycle notation).
(The involutive and fixed-point-free properties
must be proved from our original tree's properties,
which proof we delay. TODO)
@
A path from root to leaf might be empty; in that
case, the sequence is empty. Otherwise, the path
takes some sequence of lefts and rights. We
say that the sequence of a path is that list
whose first element is the pair of the node
at which the path first turns left, and whose
tail is the associated sequence of the path
from the root of the child tree to the given leaf.
@
The application of this for removing an involution
is as follows. One has given an involution in the
proper order, and a pair-tree again in proper order.
(So if we were being thorough, we would need to
define proper order and show the original tree
is properly ordered, and show that removal preserves
propriety.) If the tree is empty, you return the tree.
Otherwise, compare the root with the head of the
involution. If they differ, remove the whole involution 
from the right child. If, instead, they agree, then
remove the rest of the involution from the left child.
If the result is just a leaf, then we can get rid of this
root entirely, so the result should be the right child.
Otherwise, it's just the tree with the rest of the involution
removed from the left child.
@
<<how to remove an involution>>=
def removeInvolution(l,pt):
    if l == []:
        return pt
    if pt[0] == "PTLeaf":
        return pt
    p,ps,(str,pp,lt,rt) = l[0],l[1:],pt
    assert str == "PTBranch"
    if p != pp:
        return ("PTBranch", pp, lt, \
                removeInvolution(l,rt))
    ltp = removeInvolution(ps,lt)
    if ltp[0] == "PTLeaf":
        return rt
    else:
        return ("PTBranch", pp, ltp, rt)
<<neckl.py>>=
<<how to remove an involution>>
@
This takes time proportional to at most the number of face-pairs.
With a more sophisticated structure, we could possibly
get it down lower. At any rate, this is much better
than time proportional to the number of \emph{gluings}.
@
In conclusion for this section, it's now completely
straightforward to implement our original plan as
described above: pop top, remove orbit, do something
with the orbit representative (here encapsulated
in a function [[f]]), repeat.
@
<<how to do stuff with orbit representatives>>=
def forallOrbitReps(n,f):
    pt = originalTree(n)
    while pt[0] != "PTLeaf":
        l = leftInvolution(pt)
        lorb = orbitWithRepeats(n,l)
        for lp in lorb:
             pt = removeInvolution(lp,pt)
        f(l)

<<neckl.py>>=
<<how to do stuff with orbit representatives>>
@
\section{Vetting the manifolds}
We can now generate all the manifolds of interest to us.
So now our task is to determine among these which are
hyperbolic.
\subsection{Sanity checks}
We can first implement some basic sanity checks. All necklace
gluings are orientable. Likewise, they are all connected.
(If we were testing arbitrary MOM gluings, then we would 
add a connectedness test.) Our other requirement, though, 
is that the links of all the vertices must be tori. This
is known in the literature as a "(generalized) link complement,"
i.e. the complement of a nontrivial link in some closed orientable 3-manifold.
<<link complement>>=
def linkComplement(mfld,allowInteriorVertices):
    if not mfld.isOrientable():
        return False
    if not mfld.isConnected():
        return False
    M = Triangulation3(mfld)
    M.finiteToIdeal()
    if not M.isValid():
        return False
    vs = mfld.vertices()
    for v in vs:
        if not (v.link() == v.TORUS or (allowInteriorVertices and v.link() == v.SPHERE)):
            return False
    else:
        return True

<<unhyp.py>>=
from regina import Triangulation3
from regina import NormalSurfaces as NS
enumerate = NS.enumerate
from regina import NS_STANDARD as NSS
from regina import NS_QUAD as NSQ
from regina import NS_FUNDAMENTAL as NSF
# This computation is partially supported by NSF
from regina import NS_VERTEX as NSV
<<link complement>>
@
\subsection{Finding faults}
Now comes the real work. For a nontrivial
link complement $M$, $M$ is hyperbolic if
and only if it is irreducible, boundary
irreducible, atoroidal, and anannular.
(This is not true for closed orientable
3-manifolds, as small Seifert-fibered
spaces satisfy all these properties, yet
are not hyperbolic.)

All faults are topologically essential
surfaces in some way. There are several
interesting kinds of surfaces that are
never essential. We incorporate this
into the following easy check.

<<trivially inessential>>=
def triviallyInessential(surf):
    if surf.isVertexLinking() or \
       surf.isSplitting() or \
       surf.isThinEdgeLink()[0] != None or\
       surf.isThinEdgeLink()[1] != None:
        return True
    else:
        return False

<<unhyp.py>>=
<<trivially inessential>>
@ 
\subsubsection{Spheres, projective planes, and discs}
We first need to determine whether or
not it is reducible. Regina already has
a routine for this, but that routine is
only guaranteed to work for closed 3-manifolds.
So we roll our own, slow version here. It
is an interesting question whether or not
one could get a (comparatively) much quicker
scheme using only quad-vertex surfaces on
ideal triangulations. We do not presume to
determine this one way or the other.
We have a choice of either using standard
coordinates and fundamental surfaces, in
which case we can use ideal triangulations
(see Matveev); or we can use quad coordinates
and vertex surfaces, but we can only use
``material'' triangulations. The latter
have more tetrahedra. We use the more
familiar standard and fundamental surfaces
when we can.

The plan is simply to go through the
standard fundamental surfaces and check if
they are essential spheres or $P^2$s.

Since the construction of normal surface
lists is costly, we do not write functions
determining whether or not a 3-manifold
has an essential surface of a given type,
but rather whether a given normal surface
list has a such a surface. (One could probably
clean the following up using Regina's filter
formalism. TODO)

<<essential P2>>=
def essentialP2In(nsl):
    l = nsl
    n = l.size()
    for i in range(0,n):
        s = l.surface(i)
        x = s.eulerChar()
        if x != 2:
            if x != 1:
                continue
            if s.isOrientable():
                continue
@
At this point we know $s = P^2$. We return its index in the
normal surface iterator [[l]],
and indicate that it is $P^2$. If there is a projective
plane, it is essential (Rolfsen, Lem. 5.1).
<<essential P2>>=
            return (i,"$P^2$")
@ 
After the [[for]] loop, if we found no
projective planes, then there are none.
<<essential P2>>=
    else:
        return None

@
Now we look for essential spheres.            
<<essential S2>>=
def essentialS2In(nsl):
    l = nsl
    n = l.size()
    for i in range(0,n):
        s = l.surface(i)
        x = s.eulerChar()
        if x != 2:
            continue
        if triviallyInessential(s):
            continue
@
If the Euler characteristic is 2, then
$s$ is a sphere.
Cut $M$ along $s$ into $m$. (It is
  unfortunate here that we cut instead of crush.
  We should probably be able to crush instead. TODO)
Then $m$ has two sphere boundary components. 
We cap them off by idealizing $m$.
@
We note here that Python includes indentation
as a critical part of its syntax. It's somewhat
hard to tell in this document that the following
code is indented outside the previous
large [[if]] statement but inside the
overall [[for]] loop. The statements inside
the [[if]] are at indentation level at least 3;
the following is at indentation level 2.
<<essential S2>>=
        m = s.cutAlong()
        m.finiteToIdeal()
        m.intelligentSimplify()
@
If $m$ is connected, then $s$ was non-separating,
and hence essential.
<<essential S2>>=
        if m.isConnected():
            return (i, "non-separating $S^2$")
@
Now, suppose instead that $s$ separates $M$. Since
we assumed $M$ was connected to begin with, it
separates $M$ into two components. The sphere 
$s$ is essential precisely when neither component
of $M$ cut along $s$ is a ball. We've idealized the
cut, so this is equivalent to neither component
of $m$ being $S^3$.
<<essential S2>>=
        m.splitIntoComponents()
        m0 = m.firstChild()
        m1 = m0.nextSibling()
        if not (m0.isThreeSphere() or \
                m1.isThreeSphere()):
            return (i,"Connect-sum $S^2$")
@
The following
is at indentation level 1, outside the [[for]] loop.
This code is only run if none of the above
[[return]] statements are
encountered. In that case, there are no
essential spheres or projective planes whatever
by normal surface theory, and the manifold is irreducible.
<<essential S2>>=
    return None
    
<<unhyp.py>>=
<<essential P2>>
<<essential S2>>
@

For our sakes, developing a method to find
an essential disk is trivial,
for $M$ is assumed to be an irreducible nontrivial
link complement. In that case, $M$ admits a compressing
disc if and only if it is a solid torus, and this already
has an optimized implementation in Regina, viz. the
method [[isSolidTorus]]. The reader may wonder why
we use this instead of the more obvious
[[hasCompressingDisc]]. The reason is that, assuming
irreducibility, the [[isSolidTorus]] test can yield [[False]]
more quickly than [[hasCompressingDisc]] can,
since, among other things, [[isSolidTorus]] does homology checks.
@
\subsubsection{Finding essential tori and Klein bottles}
First, no hyperbolic nontrivial link complement has
an embedded Klein bottle. Any Klein bottle whatever
is a witness against hyperbolicity (for nontrivial
link complements). We note that if we do return a $K^2$, then
it may not necessarily be an essential $K^2$.
<<essential K2>>=
def essentialK2In(nsl):
    l = nsl
    n = l.size()
    for i in range(n):
        s = l.surface(i)
        x = s.eulerChar()
        if x != 0:
            continue
        if not s.isCompact():
            continue
        if not s.isOrientable():
            return (i,"$K^2$")
@
If the [[for]] loop has concluded, then
there is no Klein bottle.
<<essential K2>>=
    return None

@
An \emph{essential torus} is an embedded torus
that is neither compressible nor boundary parallel.
Compressibility is already implemented in Regina.
In general, boundary parallelism can be determined
using the methods of Jaco and Tollefson; however,
these have not yet been implemented in Regina.
Nevertheless, it only requires a test of homeomorphism
to $T^2 \times I$.
@
Neil Hoffman, Will Pettersson and I have found
the following faster method to test for homeomorphism
to $T^2 \times I$, and it also only uses methods
already implemented in Regina. The method works
due to results on knots in solid tori due to Gabai
(and also Berge), which we indicate below.
@
The method in practice is quite simple. We first
do some sanity checks. In particular, if we are
so fortunate to have a presentation of the fundamental
group that Regina recognises [sic] as $\mathbf{Z}^2$,
then the manifold is certainly $T^2\times I$ (by
Rolfsen 10.6 and the fact that we have two boundary
components). After the sanity checks,
we at least know the manifold has two boundary components,
both tori. Change the triangulation until the
induced triangulation $T$ on some boundary torus has one vertex.
(Here we assume Regina will take care of this
for us in its simplification routines. It makes
no guarantees like this, so we check that it
works. If it fails, we fail. This shouldn't ever happen
for our simple examples. A more general approach
is ongoing work with Neil Hoffman and William
Pettersson, implementing \emph{inflations} due
to Jaco and Rubinstein.) 
@
Closing the book along any edge $e$ in $T$ accomplishes
a Dehn filling along the slope dual to $e$ in $T$.
If $M$ is $T^2 \times I$, then every such filling
must be a solid torus. (We can think of a Dehn filling
of $T^2\times I$ as an attachment of $T^2 \times I$
to $D^2\times S^1$ instead of the other way round. Then
the $T^2\times I$ is clearly just a boundary collar.)
Conversely, if any such filling is not a solid torus,
then $M$ is demonstrably not $T^2 \times I$.
As mentioned above, we can check this with Regina.
@
If we fold along one edge and get a solid torus, then
we know $M$ is the exterior of a knot in a solid torus.
Folding along two other edges and getting a solid torus
puts $M$ in a very special class of manifolds by Gabai's
work. Finally, the actual slopes we fill along when
closing the book have intersection number $3$ with each
other. No such manifold, apart from $T^2 \times I$, admits
three such fillings. So if we get three solid tori from
the above Dehn fillings, then in fact $M$ must be $T^2\times I$.
(Regina's simplification procedures are so effective
that we suspect this point in the procedure will not be
reached for the manifolds we encounter. Nevertheless we
may as well add it for posterity.)

<<is T2xI>>=
def isT2xI(mfld):
    idl = Triangulation3(mfld)
    idl.finiteToIdeal()
    idl.intelligentSimplify()
    if not (linkComplement(idl,True) and \
        len(mfld.boundaryComponents()) == 2):
        return False
    if not mfld.homologyH1().detail() == '2 Z\n':
        return False
    if mfld.fundamentalGroup().recogniseGroup() == '2 Z':
        return True
    M = Triangulation3(mfld)
    M.idealToFinite()
    M.intelligentSimplify()
    t = M.boundaryComponents()[0]
    if t.countFaces(0) != 1:
        raise Exception("weird boundary component")
    edges = t.faces(1)
    for e in edges:
        i = e.index()
        Mp = Triangulation3(M)
        ep = Mp.face(1,i)
        Mp.closeBook(ep,False,True)
        if not Mp.isSolidTorus():
            return False
    else:
        return True
        
<<unhyp.py>>=
<<is T2xI>>

@ 
Now we look for essential tori.
<<essential T2>>=
def essentialT2In(nsl):
    l = nsl
    n = l.size()
    for i in range(n):
        s = l.surface(i)
        x = s.eulerChar()
        if x != 0:
            continue
        if not s.isCompact():
            continue
        if not s.isOrientable():
            continue
        if triviallyInessential(s):
            continue
@
Having located a fundamental normal torus,
we should test whether or not it is essential.
This boils down to whether or not it cobounds
a $\partial$-reducible 3-manifold (implying it is compressible),
or a $T^2 \times S^1$ (implying it is boundary-parallel).
@
(The reader should particularly note
that testing $\partial$-reducibility for the exterior
of a torus in an irreducible nontrivial link complement
is not the same as testing
whether or not that exterior has a solid torus component.
The exterior's components are not necessarily irreducible,
even though the original 3-manifold is irreducible.
If one of the components is reducible, the torus is called
a \emph{convolutube}.)
@
Of first concern to us
is whether or not it separates. If it doesn't,
then it is a non-separating torus and hence essential.
<<essential T2>>=
        m = s.cutAlong()
        m.intelligentSimplify()
        if m.isConnected():
            return(i,"non-separating $T^2$")
@
Having found a separating torus, we can
now test whether or not it is essential,
by testing whether the components of
$m$ are either $\partial$-compressible or
$T^2 \times I$. 
<<essential T2>>=
        m.idealToFinite()
        m.intelligentSimplify()
        m.splitIntoComponents()
        m0 = m.firstChild()
        m1 = m0.nextSibling()
        if m0.hasCompressingDisc() or m1.hasCompressingDisc() or isT2xI(m0) or isT2xI(m1):
            continue
@
If they are not, then the torus is
essential. 
<<essential T2>>=
        return (i,"essential $T^2$")
@
Otherwise, if there is no essential torus,
then return nothing. (This else is outside the [[for]] loop.)
<<essential T2>>=
    else:
        return None
        
<<unhyp.py>>=
<<essential K2>>
<<essential T2>>
@
\subsubsection{Essential annuli and M\"obius strips}
Now, as for the atoroidal remainder, there
will be hyperbolic and Seifert-fibered manifolds.
We can distinguish the Seifert-fibered manifolds by
finding essential annuli and M\"{o}bius strips in them.
Hyperbolic manifolds have no such surface.

As we are finally treating bounded surfaces,
we can no longer use ideal triangulations; the
theory of spun-normal surfaces is not yet well-enough
developed. However, we can just look among the
Q-vertex surfaces.
\begin{proposition}
  Let $T$ be a material triangulation of
  an irreducible $\partial$-irreducible
  atoroidal link complement $M$. If $M$
  admits an essential annulus, then $T$
  admits a Q-vertex essential annulus.
\end{proposition}
\begin{proof}
  Since $M$ admits an essential annulus,
  by Corollary 6.8 of Jaco-Tollefson $T$
  admits a vertex essential annulus $A$ or
  torus---but it must be an annulus, as
  $M$ is atoroidal.
  By the proof of Theorem 2 in Tollefson,
  $A$ is isotopic to a Q-vertex surface.
\end{proof}

We don't use this just yet, though, to keep
parallelism among all the fault-finding routines.
We will plug Q-vertex lists into the following
functions instead of standard fundamental lists.

<<essential M2>>=
def essentialM2In(nsl):
    l = nsl
    n = l.size()
    for i in range(n):
        s = l.surface(i)
        if not s.hasRealBoundary():
            continue
        x = s.eulerChar()
        if x != 0:
            continue
@
At this point we know [[s]] is either
an annulus or a M\"{o}bius band. If it's
not orientable, it's the latter, and is
a witness against hyperbolicity.
<<essential M2>>=
        if not s.isOrientable():
            return (i,"$M^2$")
@
After the [[for]] loop, there were no
M\"{o}bius bands. So there isn't one in the list.
<<essential M2>>=
    else:
        return None

@
Now we look for essential annuli.
<<essential A2>>=
def essentialA2In(nsl):
    l = nsl
    n = l.size()
    for i in range(n):
        s = l.surface(i)
        if not s.hasRealBoundary():
            continue
        x = s.eulerChar()
        if x != 0:
            continue
        if not s.isOrientable():
            continue
        if triviallyInessential(s):
            continue
@ 
At this point we know [[s]] is an annulus. To determine
whether or not it is essential, cut along it.
If the complement is connected, then the
annulus is nonseparating, and is thus essential.
<<essential A2>>=
        m = s.cutAlong()
        if m.isConnected():
            return (i,"non-separating $A^2$")
@
Otherwise, [[m]] is disconnected. Split it
into its components. The annulus [[s]] is
essential when neither of these components
is a ball or is a solid torus. (That is, when
[[s]] is not compressible; by the irreducibility
and $\partial$-irreducibility of our given
manifold, we can just do ball and solid torus tests.)
<<essential A2>>=
        m.splitIntoComponents()
        m0 = m.firstChild()
        m1 = m0.nextSibling()
        if m0.isBall() \
           or m0.isSolidTorus() \
           or m1.isBall() \
           or m1.isSolidTorus():
           continue
        else:
            return (i,"essential $A^2$")   
@
Finally, if we have gone through all quad-vertex
surfaces and found no essential annulus (or M\"{o}bius band),
then there is no such surface by Q-normal surface theory.
<<essential A2>>=
    else:
        return None
<<unhyp.py>>=
<<essential M2>>
<<essential A2>>

@        
\subsection{Determining hyperbolicity}
With all the fault-finding routines done,
we can now put them all together into a
hyperbolicity test for nontrivial link complements.
@
The following is a little optimized; Regina
can already recognise [sic] some fundamental
groups. Those groups that it knows are not
fundamental groups of finite-volume hyperbolic
3-manifolds. (This may change with later
versions of Regina, in which case to update
this one would have to specify the nonhyperbolic
groups Regina recognises.)
@
Also, several of the manifolds that took the longest
time to find faults for had fundamental
group presentation with a single relator that was a commutator
of the form $[a^p,b^q]$. These groups are also not
fundamental groups of finite-volume hyperbolic
3-manifolds.
@
Later on, we will need to recognize small Seifert spaces.
As far as the author knows, hoping for the best with
census searches, as below, is the state of the art in implementations
of this recognition problem, though there are algorithms
solving it. And since we need this anyhow, we go ahead
and implement it now in the hyperbolicity test.
@
We suspect that more optimization is possible
by minimizing the associated Heegaard diagram
and then checking whether or not the associated
minimized handle decomposition based on $T^2$ is full.
But as it stands, the code runs in under 10 minutes
on a Raspberry Pi, and that suffices for our purposes.
@
<<hyperbolicity>>=
def findFault(mfld):
    assert linkComplement(mfld,True)
    M = Triangulation3(mfld)
    M.finiteToIdeal()
    M.intelligentSimplify()
    l = enumerate(M,NSS,NSF)
    p2 = essentialP2In(l)
    if p2 != None:
        return p2
    s2 = essentialS2In(l)
    if s2 != None:
        return s2
    if mfld.isSolidTorus():
        return ([], "D2")
    k2 = essentialK2In(l)
    if k2 != None:
        return k2
    t2 = essentialT2In(l)
    if t2 != None:
        return t2
    M = Triangulation3(mfld)
    M.idealToFinite()
    M.intelligentSimplify()
    l = enumerate(M,NSQ,NSV)
    m2 = essentialM2In(l)
    if m2 != None:
        return m2
    a2 = essentialA2In(l)
    if a2 != None:
        return a2
    return None
@
<<hyperbolicity>>=    
def isBasicCommutator(expr):
    l = expr.terms()
    if len(l) != 4 or \
       l[0] != l[2].inverse() or \
       l[1] != l[3].inverse():
        return False
    else:
        return True

def isCommonAxisRelator(expr):
    l = expr.terms()
    return len(l) == 2

def possiblyHyperbolicPi1(mfld):
    G = mfld.fundamentalGroup()
    G.intelligentSimplify()
    if G.countGenerators() == 2:
        for i in range(G.countRelations()):
            if isBasicCommutator(G.relation(i)):
                return (False, "$\\pi_1 = \\langle a,b\\ |\\ [a^p,b^q], \ldots \\rangle$")
            if isCommonAxisRelator(G.relation(i)):
                return (False, "$\\pi_1 = \\langle a,b\\ |\\ a^p b^q, \ldots \\rangle$")
    name = G.recogniseGroup()
    if name != '':
        return (False, "$\\pi_1 =" + name + "$")
    return (True,'')

def hyperbolicity(mfld):
    if mfld.hasStrictAngleStructure():
        return (True, "strict angle structure")
    x = possiblyHyperbolicPi1(mfld)
    if not x[0]:
        return x
@
We don't know of a specification of the outputs
of the censuses in Regina, but a cursory inspection in the Regina GUI
reveals that orientable hyperbolic manifolds occur in four censuses:
the SnapPea census of cusped hyperbolic manifolds, the census of hyperbolic
knot and link complements in $S^3$, the census of closed hyperbolic
3-manifolds by Hodgson and Weeks, and the closed orientable census.
The names of the first census entries
have the usual SnapPea form. These will never occur in this routine,
as these triangulations have positive solutions to Thurston's gluing
equations, and so they certainly admit strict angle structures. The
second census has the same issue. Entries of the third census all have
the form ``number:id'' where ``number'' is a decimal approximation
of a real number (the volume), and ``ID'' is a SnapPea census manifold
with an indicated Dehn filling. Hyperbolic entries of the fourth census begin with
the string ``Hyp''. Conversely, entries for nonhyperbolic manifolds
do not have these forms.
<<hyperbolicity>>=
    ch = regina.Census.lookup(mfld)
    if ch.first() != None:
        nm = ch.first().name()
        if nm.find('Hyp') != -1:
       	    return (True, nm)
        try:
            vol = float(nm[:nm.index(':')])
            return (True, nm)
        except:
            return (False, nm)
    s = findFault(mfld)
    if s != None:
        return (False, s)
    else:
        return (True, "no faults")

<<unhyp.py>>=
<<hyperbolicity>>
@
\section{Nonelementary embeddings}
The above was a nice warmup. But for our problem,
we don't need hyperbolic necklaces---we need necklaces
that embed nonelementarily into hyperbolic manifolds.
For Mom-$n$ anifolds with $n\leq 4$, Gabai, Meyerhoff, and Milley
were able to show this is a trivial distinction, using
normal surface theory and a notion of complexity due to
Matveev. However, bead-number 7 structures are Mom-5s,
and the distinction is nontrivial in general. 
@
There is an algorithm that, given
a triangulation $T$ of a link-complement $M$, will
return a finite list $L$ of finite-volume hyperbolic
3-manifolds such that the hyperbolic 3-manifolds
into which $M$ embeds nonelementarily are exactly
the hyperbolic Dehn fillings of elements of $L$. However, this
algorithm is quite complicated, due to its dependence
upon a $S^3$-link complement algorithm whose foundations
were laid by R. Budney.
@
Thus, instead, we are going to implement a simpler algorithm
$NE$ that returns not $L$ but a finite superset of $L$.
@
\subsection{Review}
Recall the following.
@
\begin{definition}
  Suppose $\phi: (M, S) \hookrightarrow (N,T)$ is a proper embedding
  of $M$, with $S,T$ torus components of $\partial M$, $\partial N$
  respectively. This embedding is \emph{nonelementary} when
  the induced map $\phi_\ast: \pi_1(M) \to \pi_1(N)$
  has nonabelian image.
\end{definition}
@
What we have shown in the preceding work is not just that
$N$ of low cusp volume admits an embedding from a necklace
manifold of bead number at most 7, but also that it admits
a \emph{nonelementary} such embedding. So the results of
running $NE$ on all the necklace manifolds of bead number
at most 7 and concatenating these lists together will yield
a finite list of Dehn parents for hyperbolic 3-manifolds
of low cusp volume.
@
\begin{lemma}
  Suppose $\phi: (M,S) \hookrightarrow (N,T)$ is a nonelementary
  embedding in a hyperbolic link complement $N$, with $M$ also
  a link complement.
  
  There is a nonelementary embedding
  $\phi': (M,S) \hookrightarrow (N,T)$ with
  $\phi'(\pi_1(M)) = \phi(\pi_1(M))$ and such that
  for every boundary torus $t$ of $M$, $\phi'(t)$
  either is boundary parallel in $N$, or bounds
  a solid torus in $N$. 
\end{lemma}
@
We call such an embedding a \emph{Dehn embedding}.
@
\begin{lemma}
  Suppose $\phi: (M,S) \hookrightarrow (N,T)$ is a Dehn
  embedding in a hyperbolic link complement $N$,
  with $M$ also a link complement.
  \begin{enumerate}
    \item $M$ admits no $\mathbf{RP}^2$ or $K^2$.
    \item Suppose $M$ admits an essential sphere $\sigma$.
      \begin{enumerate}
      \item $M$ is a connect-sum along $\sigma$.
      \item Letting $M'$ be that summand containing $S$,
        there is a Dehn embedding
        $\phi': (M',S) \hookrightarrow (N,T)$.
      \item The other summand is an $S^3$ link complement.
      \end{enumerate}
    \item If $M$ is irreducible, then it is $\partial$-irreducible.
    \item Suppose $M$ is irreducible
      and admits an essential torus $\tau$.\label{itm:essT2}
      \begin{enumerate}
      \item $\tau$ separates $M$.
      \item Letting $M'$ be that component containing $S$
        and the other component be $M''$,
        one of the following is true:
        \begin{enumerate}
        \item There is a Dehn embedding
          $\phi': (M',S) \hookrightarrow (N,T)$,
          and $M''$ is the complement of a link
          in $D^2\times S^1$.
        \item There is a Dehn embedding
          $\phi': (M'',\tau) \hookrightarrow (N,T)$,
          and $M'$ is the complement of a link
          in $T^2 \times I$.
        \end{enumerate}
      \end{enumerate}
    \item Suppose $M$ is irreducible and atoroidal.
      Then $M$ is hyperbolic.
    \end{enumerate}
\end{lemma}
@
In order to get a full nonelementary embedding recognition
algorithm, one would need to refine this lemma in part \ref{itm:essT2}
to account for \emph{how} the two components get identified
along their particular torus boundaries. This would start to
involve a computation of the \emph{companionship graph} of the
JSJ-decomposition of $M$, an involved process (see \cite{Budney}).
We do not go into this here and content ourselves with using
the above lemma.
@
The proof comes more or less verbatim from the introductory
lemmas of \cite{GMM11}.
@
\subsection{The naive pseudocode}
Here is a naive pseudocode sketch of an approach to
getting $NE$. Recall that $NE$ should return a list of
hyperbolic manifolds whose Dehn fillings include
all hyperbolic link complements into which the given manifold
embeds nonelementarily. Happily, we also already know
that torus boundary component that should get sent to
the small cusp, namely the polar cusp of a necklace manifold.
So we can give that as input to the procedure, and implement
it following the lemma without much thought.
\begin{verbatim}
Naive(M,S):
    if there is P2 or K2 in M:
        return []
    else if there is nonseparating S2 or T2 in M:
        return []
    else if there is essential separating S2 `s' in M:
        let M', M'' be components of M - s /
            with M' that component containing S
        if M'' not S3 link complement:
            return []
        else:
            return Naive(M',S)
    else if M is D2 x S1:
        return []
    else if there is essential T2 `t' in M:
        let M', M'' be components of M - t /
            with M' that component containing t
        X,Y = [],[]
        if M'' is D2 x S1 link complement:
            X = Naive(M',S)
        if M' is T2 x I link complement:
            Y = Naive(M'',t)
        return union(X,Y)
    else if there is essential M2 or A2 in M:
        return []
    else:
        return [M]
\end{verbatim}
@
\subsection{Less naive pseudocode}
Unfortunately we don't have a nice implementation
of determining whether or not $M''$ is a certain
kind of link complement. Instead, we will have
some heuristic guess, which we hope will tell us
whether or not a manifold is a given type of
link complement. We call this being (or not
being) an ``obvious'' link complement of the given type.
If a manifold is obviously \emph{not} such a manifold,
then we can proceed as in the naive pseudocode. Otherwise
we must give the manifold the benefit of the doubt---it
might be such a link complement. We could
say that we recur on $NE$ when the other component is ``not
obviously not'' a link complement of given type. But this
awkward construction is captured neatly by [[else]] statements
in the pseudocode.
\begin{verbatim}
NE(M,S):
    if there is P2 or K2 in M:
        return []
    else if there is nonseparating S2 or T2 in M:
        return []
    else if there is essential separating S2 `s' in M:
        let M', M'' be components of M - s /
            with M' that component containing S
        if M'' is obviously not an S3 link complement
            return []
        else:
            return NE(M',S)
    else if M is D2 x S1:
        return []
    else if there is essential T2 `t' in M:
        let M', M'' be components of M - t /
            with M' that component containing t
        X,Y = [],[]
        if M'' is obviously not a D2 x S1 link complement:
            return []
        else:
            X = NE(M', S)
        if M' is obviously not a T2 x I link complement:
            return []
        else:
            Y = NE(M'',t)
        return union(X,Y)
    else if there is essential M2 or A2 in M:
        return []
    else:
        return [M]
\end{verbatim}
@
\subsection{Obvious non-link-complements}
First, we should define what it means to be
obviously not a ------ link complement with
the blank filled variously by $S^3$, $D^2\times S^1$,
and $T^2\times I$. We could just say that this
is \emph{never} obvious and get a correct procedure,
but we can do better than that.

First of all, if $M$ is closed and not $S^3$, then
it is obviously not an $S^3$ link complement! Likewise,
if it has at most one boundary torus and isn't $D^2\times S^1$,
then it is obviously not a $D^2\times S^1$ link complement, and similarly
if it has at most two boundary tori and isn't $T^2\times I$,
then it is obviously not a $T^2\times I$ link complement.

Likewise, we should check that the homology of the manifold agrees
appropriately with Alexander duality. ($D^2\times S^1$- and
$T^2\times I$-link complements are themselves $S^3$-link complements.)

Finally, we can
also try to identify the fundamental group of the manifold;
this is itself an identification in a census (of presentations).
<<obvious link complement tests>>=
from unhyp import isT2xI
def obvious_isLinkIn(M,amb):
    s3 = "S^3"
    d2s1 = "D^2 x S^1"
    t2i = "T^2 x I"
    try:
        assert amb in [s3, d2s1, t2i]
    except AssertionError:
        raise Exception("Only S^3, D^2 x S^1, and T^2 x I allowed as second argument")
    if not linkComplement(M,True):
        return False
@        
After the above sanity check (really, a type-check),
we do the boundary-component tests.
<<obvious link complement tests>>=
    nbc = M.countBoundaryComponents()    
    if amb == s3:
        if nbc == 0:
            if not M.isThreeSphere():
                return False
            else:
                return True
    if amb == d2s1:
        if nbc == 0:
            return False
        if nbc == 1:
            if not M.isSolidTorus():
                return False
            else:
                return True
    if amb == t2i:
        if nbc in [0,1]:
            return False
        if nbc == 2:
            if not isT2xI(M):
                return False
            else:
                return True
@ 
Now having checked the boundary components
are appropriate, we make sure the manifold's
homology agrees with Alexander duality. Recall
that by Alexander duality, if $M$ is an $S^3$-link 
complement (which includes $D^2\times S^1$-
and $T^2\times I$-link complements), then
\[
H_1(M; \mathbf{Z}) = \mathbf{Z}^{|\pi_0(\partial M)|}
\mbox{ and } H_2(M; \mathbf{Z}) = \mathbf{Z}^{|\pi_0(\partial M)|-1}.
\]
<<obvious link complement tests>>=
    h1 = M.homologyH1()
    if h1.countInvariantFactors() > 0 \
       or h1.rank() != nbc:
       return False
    h2 = M.homologyH2()
    if h2.countInvariantFactors() > 0 \
       or h2.rank() != nbc-1:
       return False
@ 
If at this point we haven't determined
whether or not the manifold is a link
complement in whichever ambient manifold,
then we give up. (Later on, if need be,
one could implement census lookups here.)
<<obvious link complement tests>>=
    else:
        return None
<<nonelem.py>>=
<<obvious link complement tests>>
@
\subsection{Actually implementing [[NE]]}
The code for [[NE]] is much the same
as for the hyperbolicity algorithm, except
that instead of terminating when we find
a fault, we cut along the fault and examine
the components recursively.

We also note that the following implementation
is significantly different from the above
``less naive'' pseudocode, as this implementation
does not account for which boundary component
of $M$ is $S$. This could possibly include
extraneous manifolds in the resulting list---but
it is still a superset of Dehn parents as desired.
(We don't account for $S$ as Regina's surface cutting
methods complicate the boundary. With more work one
could keep track of which surface is which.)
@
<<NE>>=
import regina as rg
from unhyp import *
nsl = rg.NormalSurfaces.enumerate
@ 
First we will do a census check, as follows.
<<census check>>=
def censusNE(mfld):
    if rg.versionString() != "5.1":
        raise Exception("Censuses not vetted for Regina versions not equal to 5.1")
    ch = rg.Census.lookup(mfld)
    if ch.first() == None:
        return None
    name = ch.first().name()
@  
There is no documentation of the types of names
in Regina's censuses. As of version 5.1, an inspection
of their names in the Regina GUI reveals that all the
names of census manifolds are of the following types.
From the closed orientable census, the names are
\begin{enumerate}
\item $S^3$;
\item $L(p,q)$ for some $p,q \in \mathbf{N}$;
\item $RP^3$;
\item $SFS(S: (a_0, b_0), \ldots, (a_n, b_n))$ for some number $n+1$ of singular fibers and some
  compact surface $S$;
\item $T \times S^1$;
\item $K \tilde{\times} S^1$;
\item $T \times [0,1] / \phi$ for some $\phi: T \times \{0\} \to T \times \{1\}$;
\item $X \cup_\phi Y$ for bounded manifolds $X,Y$
  and $\phi: \partial X \to \overline{\partial Y}$; and
\item Hyp\textunderscore$\rho$ for some real number $\rho$, the hyperbolic volume of the manifold.
\end{enumerate}
All the other orientable censuses are of hyperbolic 3-manifolds. The Hodgson-Weeks census has
entries $\rho:N$ where $\rho$ is a decimal approximation of the hyperbolic volume and $N$ is
an expression of the manifold as a Dehn filling of some SnapPea census manifold. The cusped
census has the usual SnapPea census names. The link census has the usual link names. The latter
is the only difficulty for us; we must make sure to distinguish the two types of name beginning
with $L$, viz. lens spaces and hyperbolic link complements with more than one boundary component.
Apart from that, with the current censuses in Regina 5.1, we see that the only census manifolds
that embed nonelementarily in a hyperbolic link complement are themselves hyperbolic.
<<censuscheck>>=
    if name.find("Hyp") != -1:
        return (True, name)
    try:
        vol = float(name[:name.find(':')])
        return (True, name)
    except:
        pass
    if name[0] == "L" and name[1] != "(":
        return (True, name)
    return (False, name)
    
<<NE>>=
def NE(mfld):
    Mi = rg.Triangulation3(mfld)
    Mi.intelligentSimplify()
    Mi.finiteToIdeal()
    Mi.intelligentSimplify()
    x = censusNE(Mi)
    if x != None:
        return x[0]
@ 
Next, we check to see
whether or not $M$ admits a strict angle
structure. If it does, then $M$ is hyperbolic,
and every hyperbolic $N$ into which $M$ embeds nonelementarily
is a hyperbolic Dehn filling of $M$. This is a relatively
quick check.
<<NE>>=
    if Mi.hasStrictAngleStructure():
        return [mfld]
@
Next, before any normal surface enumeration,
we check to see if $M$'s fundamental group
is recognizable as above in the hyperbolicity
section. If so, then not only is $M$ not hyperbolic,
but also $M$ does not even embed nonelementarily
into any hyperbolic link complement.
<<NE>>=
    x = possiblyHyperbolicPi1(mfld)
    if not x[0]:
        return []
@ 
We set up two normal surface collections:
first, the fundamental-standard collection for an ideal
triangulation of $M$, or the FSI collection; and, much 
later, the quad-vertex collection for a material 
triangulation of $M$ (which Regina
calls a ``finite'' triangulation). We call that the
QVM collection. We can find all
essential surfaces we need in the QVM collection;
however, we suspect the FSI collection is smaller,
and it contains all the essential \emph{closed}
surfaces that we need.
<<NE>>=
    Li = nsl(Mi,rg.NS_STANDARD,rg.NS_FUNDAMENTAL)
@ 
Next, we look for obviously bad surfaces.
Assuming $M$ is orientable, we can lump these
bad surfaces all together as closed non-separating
surfaces of nonnegative Euler characteristic.
<<NE>>=
    assert mfld.isOrientable()
    for i in range(Li.size()):
        s = Li.surface(i)
        x = s.eulerChar()
        if (not s.hasRealBoundary()) and x >= 0 \
          and s.cutAlong().isConnected():
            return []
@ 
Next, we look for an essential, connect-sum sphere.
But we already know how to do this. Then we cut along
it and test the components for being link complements
as in the above pseudocode.
@
<<NE>>=
    s2 = essentialS2In(Li)
    if not s2 == None:
        s2 = Li.surface(s2[0])
        MM = s2.cutAlong()
        MM.intelligentSimplify()
        MM.splitIntoComponents()
        mp = MM.firstChild()
        mpp = mp.nextSibling()
        Xp = obvious_isLinkIn(mp,"S^3")
        Xpp = obvious_isLinkIn(mpp,"S^3")
        Lp, Lpp = [],[]
        if Xp != False:
            Lpp = NE(mpp)
        if Xpp != False: 
            Lp = NE(mp)
        return Lp + Lpp
@
We follow this up with a boundary irreducibility
test. If we finish the above $S^2$ search with no
essential $S^2$, then $M$ is irreducible. So
it is $\partial$-irreducible if and only if
it is a solid torus.
<<NE>>=
    if mfld.isSolidTorus():
        return []
@
Next, we look for an essential separating $T^2$.
We already found no non-separating $T^2$. So all
the tori in our list are separating. It remains
to find an essential torus among these. But we
already know how to do this. If we find such
a torus, then we cut along it, and test the
components for being link-complements. This
implementation differs from the above pseudocode
in that no $T^2\times I$-link complement test
is performed. That is because we cannot yet keep
track of boundary components in Regina under cutting.
<<NE>>=
    t2 = essentialT2In(Li)
    if t2 != None:
        t2 = Li.surface(t2[0])
        MM = t2.cutAlong()
        MM.intelligentSimplify()
        MM.splitIntoComponents()
        mp = MM.firstChild()
        mpp = mp.nextSibling()
        Xp = obvious_isLinkIn(mp,"D^2 x S^1")
        Xpp = obvious_isLinkIn(mpp,"D^2 x S^1")
        Lp, Lpp = [],[]
        if Xp != False:
            Lpp = NE(mpp)
        if Xpp != False: 
            Lp = NE(mp)
        return Lp + Lpp
@
Finally, if there are no obviously bad surfaces,
nor essential separating $S^2$s nor $T^2$s nor
essential discs, then $M$ is irreducible,
$\partial$-irreducible, and (geometrically) atoroidal.
Thus $M$ is either hyperbolic or atoroidal Seifert-fibered. 
We can distinguish these two cases, with our assumptions
on $M$, using surfaces: it is Seifert-fibered if and only 
if it admits an essential annulus or M\"{o}bius band. By
Q-normal surface theory we can always find such a surface
among quad-vertex surfaces, under our assumptions on $M$.

Most importantly, a Seifert-fibered manifold admits
no nonelementary embeddings into a hyperbolic link complement.
<<NE>>=
    Mf = rg.Triangulation3(mfld)
    Mf.intelligentSimplify()
    Mf.idealToFinite()
    Mf.intelligentSimplify()
    Lf = nsl(Mf, rg.NS_QUAD, rg.NS_VERTEX)
    m2 = essentialM2In(Lf)
    if m2 != None:
        return []
    a2 = essentialA2In(Lf)
    if a2 != None:
        return []
@ 
If we have found no ``faulty'' surfaces,
then $M$ is hyperbolic.
<<NE>>=
    return [mfld]

@
That concludes the procedure [[NE]].
<<nonelem.py>>=
<<NE>>
@
\section{Exceptional fillings}
We wish to determine the one-cusped
hyperbolic Dehn fillings $N$ of some
two-cusped hyperbolic 3-manifolds $M$
with more than 8 exceptional slopes.

Fix $M$. If $s$ is a slope on a boundary
torus $t$ of $M$ with length
greater than 6, then $M(s)$ is hyperbolic
by the 6 Theorem. The exceptional
slopes $s'$ of $M(s)$ we may identify
with exceptional Dehn filling
coefficients $s+s'$ on $M$. There are at
most as many of these as there are
short slopes $s'$ on the other boundary
torus $t'$ of $M$. So first we
will examine how many short slopes are
on each boundary torus. For every
two-cusped manifold we inspect and
for each of its boundary tori, this
number is always at most 8.

We now describe a simple, efficient
approach to enumerating short slopes
inspired by the first chapter of \cite{ConwayFung},
where the reader can find a more geometric
intuition for the following.

Let $T$ be the subset of $M_{2\times 2}\mathbf{N}$ consisting
of determinant one matrices. Suppose $M \in T$.
Let
\[
M = \begin{pmatrix}
  a & b \\
  c & d
\end{pmatrix}.
\]
Then $ad - bc = 1$, so $a/c = b/d + 1/(cd) > b/d$.
The \emph{interval of $M$} is the open interval
$I(M) = (b/d, a/c)$. Furthermore, again since $ad - bc = 1$,
$b/d < (a+b)/(c+d) < a/c$.
The \emph{right child of $M$} is the matrix
\[R(M) = \begin{pmatrix}
  a & a+b \\
  c & c+d
\end{pmatrix}
\]
and the \emph{left child of $M$} is the matrix
\[L(M) = \begin{pmatrix}
  a+b & b \\
  c+d & d
\end{pmatrix}
\]
By the above considerations, $L(M) \cap R(M) = \emptyset$
and $L(M) \cup \{(a+b)/(c+d)\} \cup R(M) = I(M)$.
In particular, $L(M)$ and $R(M)$ are strict subsets of
$I(M)$.

We regard $T$ as a digraph whose vertices are elements
of $T$ and with edges from a vertex to its left child
and right child.
\begin{lemma}
  $T$ is an infinite binary (search) tree whose root is
  the identity matrix.
\end{lemma}
\begin{proof}
  Note that the interval of the identity matrix
  is $(0,\infty)$, and every nonidentity matrix
  has interval being a strict subset of this interval.
  So the identity is a child of no vertex.

  Suppose $M$ is as above. Since $M$ has
  determinant 1, its columns are not equal.
  Furthermore, either $a > b$ or $b \geq a$.
  If $a > b$,             

  \end{proof}

<<excFill.py>>=
def 

@
\section{Going through the manifolds}
\subsection{Automating enumeration}
Now it's straightforward to go through the
manifolds. First we make a file
which just automates the enumeration
from the command line. It is fairly kludgy,
but perhaps that is to be expected; it makes
\LaTeX\ files. The file [[enumSummary.tex]] is
a summary of the enumeration, and the file
[[allData.tex]] is the whole set of data.
For later purposes, we also output a
file [[parents.py]] which defines
a list, the $i$th entry of which is the
list of (potential) parents for hyperbolic
link complements admitting bead-$i$ necklace
structures (up to isomorphism). We use this later.
<<vetting.py>>=
from neckl import forallOrbitReps
from neckl import makeNecklace
from unhyp import linkComplement
from unhyp import hyperbolicity
from nonelem import NE
from time import clock
@ 
First we define a procedure [[vetNecklaces]] that goes
through the $n$-bead necklaces, and
returns a pair of lists, one of hyperbolic parents
(not necessarily necklace manifolds)
and one of unhyperbolic, ``barren'' necklaces
that do not embed nonelementarily. Each
entry of each list is a triple of
a gluing, a reason why that gluing
is in the list, and a number representing
how long it took to investigate this gluing.
It also takes a debugging flag [[wstat]] to
tell whether or not we want it to display
its progress by printing out all the involutions
it investigates as it goes through them.

<<vetting.py>>=
from sys import stdout
def vetNecklaces(n,wstat=False):
    parents = []
    barren = []
    def vetInv(inv,p,b):
        if wstat:
            print str(inv)
        mfld = makeNecklace(inv)
        if not linkComplement(mfld,False):
           if wstat:
               print "invalid\n"
           return None
        before = clock()
        mfld.intelligentSimplify()
        ps = NE(mfld)
        elapsed = clock() - before
        if ps != []:
            p.append((inv,ps,elapsed))
            status = " parent\n"
        else:
            b.append((inv,ps,elapsed))
            status = " barren\n"
        if wstat:
            print status
        stdout.flush()
    vi = lambda inv: vetInv(inv,parents,barren)
    forallOrbitReps(n,vi)
    return (parents,barren)
@ 
Now for the severely kludgy part. We define
some functions that write \LaTeX\ to a given file.
<<vetting.py>>=
def invToString(inv):
    s = "$"
    for p in inv:
        s = s + "(" + str(p[0]) + "\ " + str(p[1]) + ")"
    s = s + "$"
    return s
    
def fullDisplay(outfile,vettedlist):
    f,l = outfile, vettedlist
    if len(l) == 0:
        return None
    f.write("\\begin{itemize}\n")
    for x in l:
        ln0 = "\\item \\begin{itemize}"
        ln1 = "      \\item " + invToString(x[0])
        if type(x[1][1]) == str:
            ln2 =  "      \\item " + x[1][1]
        else:
            ln2 =  "      \\item " + x[1][1][1]
        ln3 = "      \\item Time to vet was {0} seconds.".format(x[2])
        ln4 = "\\end{itemize}"
        lns = [ln0,ln1,ln2,ln3,ln4]
	lns = map(lambda s:s + "\n", lns)
	f.writelines(lns)
    f.write("\\end{itemize}\n")

def summaryPreamble(f,l,tp):
    if len(l) == 0:
        return None
    f.write("\\subsection{")
    f.write("{0} manifolds with bead number {1}".format(tp[0],tp[1]))
    f.write("}\n")
    
def recognitionTypes(f,l):
    if len(l) == 0:
        return None
    if len(l) == 1:
        x = l[0]
        ln0 = "There was one such manifold, with {0}, ".format(x[1][1])
        ln1 =  "namely, " + invToString(x[0]) + ". "
        f.writelines([ln0,ln1])
        return None
    ln0 = "There were {0} such manifolds. ".format(len(l))
    ln1 =  "Their recognition types were as follows."
    ln2 =  "\\begin{itemize}"
    f.writelines([ln0,ln1,ln2])
    recTypes = {}
    for tup in l:
        rct = tup[1][1]
        if not rct.__class__ is str:
            assert rct.__class__ is tuple
            rct = rct[1]
        if not rct in recTypes:
            recTypes[rct] = 1
        else:
            recTypes[rct] = recTypes[rct] + 1
    for rct in recTypes:
        f.write("\\item With {0}, there were {1} manifolds.\n".format(rct,recTypes[rct]))

from numpy import log2
def timesTaken(f,l,tp):
    if len(l) == 0:
        return None
    if len(l) == 1:
        f.write("It took {0} seconds to vet.".format(l[0][2]))
        return None
    ln0 = "\\end{itemize}"
    ln1 = "The times they took were approximately as follows."
    ln2 = "\\begin{itemize}"
    f.writelines([ln0,ln1,ln2])
    times = {}
    for x in l:
        timeTaken = x[2]
        approxLogTimeTaken = int(log2(timeTaken))
        altt = approxLogTimeTaken
        if not altt in times:
            times[altt] = [x[0]]
        else:
            times[altt].append(x[0])
    for altt in times:
        f.write("\\item Of manifolds vetted in about $2^{")
        f.write(str(altt)+"}")
        f.write("$ seconds, there were {0}.\n".format(len(times[altt])))
    f.write("\\end{itemize}\n")

    longTime = -2
    wasLongTime = False
    for altt in times:
        if altt > longTime:
            wasLongTime = True
    if wasLongTime == True:
        f.write("Those that took an unusual amount of time are as follows.\n")
        f.write("\\begin{itemize}\n")
        for altt in times:
            if altt > longTime:
                f.write("\item The manifolds that took about $2^{")
                f.write(str(altt) + "}$ seconds were as follows.\n")
                f.write("\\begin{itemize}\n")
                for inv in times[altt]:
                    f.write("\\item " + invToString(inv) + "\n")
                f.write("\\end{itemize}\n")
        f.write("\\end{itemize}\n")

    if tp[0] == "Hyperbolic":
        f.write("In summary, the associated involutions were as follows:\n")
        f.write("\\begin{itemize}\n")
        for x in l:
            f.write("\\item " + invToString(x[0]) + "\n")
        f.write("\\end{itemize}\n")

def vettingResultsSummary(f,l,tp):
    summaryPreamble(f,l,tp)
    recognitionTypes(f,l)
    timesTaken(f,l,tp)
@     
And finally (and still kludgily), we have
the [[main]] function for [[vetting.py]].
<<vetting.py>>=
import sys
if __name__ == "__main__":
    if not len(sys.argv) == 2:
        raise(Exception("Only one argument"))
    x = int(sys.argv[1])
    texH = open("hyperbolics.py",'w')
    hyp = []
    unh = []
    for i in range(x+1):
        (h, u) = vetNecklaces(i)
        hyp.append(h)
        unh.append(u)
    texH.write("hypInvs = [\\\n")
    hypInvs = map(lambda l: map(lambda trp: trp[0],l),hyp)
    for hypInvL in hypInvs:
        if hypInvL == []:
	    texH.write("[],\\\n")
	    continue
        texH.write("[\\\n")
	for inv in hypInvL:
	    texH.write(str(inv) + ",\\\n")
        texH.write("],\\\n")
    texH.write("]\n")
    texH.close()
    texS = open("enumSummary.tex",'w')
    texD = open("allData.tex",'w')
    preamble = ["\\documentclass{article}", \
                "\\begin{document}"]
    texS.writelines(preamble)
    texD.writelines(preamble)
    texS.write("\\section{Summary of results}\n")
    for i in range(x+1):
        vettingResultsSummary(texS,hyp[i],("Hyperbolic",i))
        vettingResultsSummary(texS,unh[i],("Unhyperbolic",i))
    texS.write("\\end{document}\n")
    texS.close()
    texD.write("\\section{All data}\n")
    for i in range(x+1):
        texD.write("\\subsection{" + "Hyperbolics of bead number {0}".format(i) + "}\n")
        fullDisplay(texD,hyp[i])
        texD.write("\\subsection{" + "Non-hyperbolics of bead number {0}".format(i) + "}\n")
        fullDisplay(texD,unh[i])
    texD.write("\\end{document}\n")
    texD.close()
@
\subsection{Naming the hyperbolics}
That took care of the classification as such. However, we would also
like to identify the hyperbolic manifolds in the SnapPea census; they
have such identifications since they have at most 8 tetrahedra.
We do this separately from vetting the manifolds, as SnapPy does not
compile yet on ARM chips, due to the [[ManifoldHP]] class.
<<naming.py>>=
from hyperbolics import hypInvs
from snappy import Manifold
from neckl import makeNecklace
from vetting import invToString

def giveName(inv):
    reginaM = makeNecklace(inv)
    reginaM.intelligentSimplify()
    snapM = Manifold(reginaM.snapPea())
    l = snapM.identify()
    if l == []:
        return (snapM.isometry_signature(),snapM.num_cusps())
    else:
        return (l[0].name(),snapM.num_cusps())

def giveNames(invL):
    named = {}
    for inv in invL:
        name = giveName(inv)
        if not name in named:
            named[name] = [inv]
        else:
            named[name].append(inv)
    return named

if __name__ == "__main__":
    f = open("hypNames.tex","w")
    f.write("\\documentclass{article}\n")
    f.write("\\begin{document}")
    namesSoFar = set()
    for hL in hypInvs:
    	newNames = set()
        repeatNames = set()
        if hL == []:
            continue
        n = len(hL[0])
        f.write("\\section{Hyperbolics of bead number " + str(n) + "}\n")
        named = giveNames(hL)
	for nm in named:
	    if nm in namesSoFar:
	        repeatNames.add(nm)
	    else:
	        newNames.add(nm)
		namesSoFar.add(nm)
	f.write("There were " + str(len(named)) + " gluings,\n")
	f.write("and " + str(len(newNames)) + " new gluings.\n")
	f.write("Their names are as follows, along with\n")
	f.write("the number of associated gluings\n")
	f.write("of bead number " + str(n) + ".\n")
	def writeNames(s):
            if s == set():
	        return None
	    f.write("\\begin{quotation}\n")
	    namel = list(s)
            namel.sort()
            for (name, num_cusps) in namel[:-1]:
                nmc = (name, num_cusps)
                f.write("\\textbf{" + name + "}: ")
	        f.write(str(len(named[nmc])) + ";\n")
	    f.write("\\textbf{" + namel[-1][0] + "}: ")
	    f.write(str(len(named[namel[-1]])) + ".\n")
	    f.write("\\end{quotation}\n")
	f.write("\\subsection{New names}\n")
	writeNames(newNames)
	f.write("\\subsection{Old names}\n")
	writeNames(repeatNames)
	f.write("\\subsection{Gluings' names}\n")
        f.write("\\begin{itemize}\n")
	def writeGluings(s):
	    namel = list(s)
	    namel.sort()
	    for (name, num_cusps) in namel:
		nmc = (name, num_cusps)
		f.write("\\item \\textbf{" + name + "}, ")
		if len(named[nmc]) > 1:
		    f.write("{0} gluings; ".format(len(named[nmc])))
		f.write("{0} cusps\n".format(num_cusps))
		f.write("\\begin{itemize}\n")
		for inv in named[nmc]:
		    f.write("\\item " + invToString(inv) + "\n")
		f.write("\\end{itemize}\n")
        writeGluings(newNames)
	writeGluings(repeatNames)
        f.write("\\end{itemize}\n")
    f.write("\\section{All the names together}\n")
    f.write("There were " + str(len(namesSoFar)) + " manifolds in all.\n")
    f.write("Their names are as follows.\n")
    f.write("\\begin{quotation}\n")
    namel = list(namesSoFar)
    namel.sort()
    for (name, num_cusps) in namel[:-1]:
        f.write("\\textbf{" + name + "},\n")
    f.write("\\textbf{" + namel[-1][0] + "}.\n")
    f.write("\\end{quotation}\n")
    f.write("\\end{document}\n")
    f.close()
@
\section{Compiling everything}
To compile everything, run the following script.
<<compile.sh>>=
#!/bin/sh
noweave -delay nonelem.nw > nonelem.tex
pdflatex nonelem.tex; pdflatex nonelem.tex; pdflatex nonelem.tex
notangle -Rneckl.py nonelem.nw > neckl.py
notangle -Runhyp.py nonelem.nw > unhyp.py
notangle -Rvetting.py nonelem.nw > vetting.py
notangle -Rnaming.py nonelem.nw > naming.py
touch enumSummary.tex
touch allData.tex
touch hyperbolics.py
python vetting.py 8
pdflatex enumSummary.tex; pdflatex allData.tex
touch hypNames.tex
python naming.py
pdflatex hypNames.tex
@ 
\end{document}
